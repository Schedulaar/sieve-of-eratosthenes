
\documentclass[a4paper,12pt]{article} 
\usepackage[top = 2.5cm, bottom = 2.5cm, left = 2.5cm, right = 2.5cm]{geometry} 

\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage{algorithm,algpseudocode}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{xcolor}
\newtheorem{proposition}{Proposition}

\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{multirow} 
\usepackage{booktabs}
\usepackage{graphicx} 
\usepackage{listings}
\lstset{language=C++,
	numbers=none,
	showspaces=false,
	showstringspaces=false,
	basicstyle=\footnotesize}

\usepackage{setspace}
\setlength{\parindent}{0in}

\usepackage{float}

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}

\usepackage{mathtools}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}
\newcommand{\bigO}{\mathcal{O}}
\lhead{\footnotesize The Sieve of Eratosthenes}
\rhead{\footnotesize Michael Markl} 


\cfoot{\footnotesize \thepage} 


\newcommand{\todo}[1]{{\color{red}#1}}

\DeclareMathOperator{\currPrime}{currPrime}
\DeclareMathOperator{\currCoord}{currCoord}
\DeclareMathOperator{\lastCoord}{lastCoord}
\DeclareMathOperator{\crosses}{crosses}
\renewcommand{\lstlistingname}{Program}
\newcommand{\algorithmautorefname}{Algorithm}
\newcommand{\propositionautorefname}{Proposition}


\begin{document}

\thispagestyle{empty}

\begin{tabular}{p{15.5cm}} %
{\large \bf Parallel Algorithms} \\
University of Utrecht \\ Fall 2020  \\ Rob H. Bisseling\\
\hline
\\
\end{tabular}

\vspace*{0.3cm}
\begin{center}
	{\Large \bf The Sieve of Eratosthenes}
	\vspace{2mm}
	
	{\bf Michael Markl}
\end{center}  
\vspace{0.4cm}

\section{An ancient primality test}

Prime numbers play a central role for example in modern encryption algorithms.
Most encryption algorithms need prime numbers with about 1,000 digits as a secret key.
Hence, many algorithms chose some number randomly and then check with so-called primality tests, whether this number is a prime number and therefore suitable for using as an encryption key.

One such primality test, which was already invented by the ancient greeks, is called the Sieve of Eratosthenes.
This algorithm not only checks for a given number whether it is prime, but it even finds all prime numbers up to that number.
Given the number $n$ the procedure starts with a list of the numbers from $2$ to $n$.
It starts with $2$ and cross out all larger multiples of $2$.
Then it continues with the next number which is not crossed out -- in the second iteration the number $3$ -- and crosses out all larger multiples of it.
This procedure is repeated until the whole list is worked through.
Then all numbers that are not crossed out in the end are exactly all prime numbers up to the number $n$.

For generating all prime numbers up to $n$ it even suffices to iterate this procedure until the number~$\floor{\sqrt{n}}$: If we assume, that $x\leq n$ is not a prime number, we find numbers $a,b\in\{2, \dots, x\}$ with $x=a\cdot b$.
If $a$ or $b$ is smaller than or equal to $\floor{\sqrt{n}}$ then $x$ would be crossed out after reaching $\floor{\sqrt{n}}$.
Otherwise, $a$ and $b$ are strictly larger than $\floor{\sqrt{n}}$ which implies that $a$ and $b$ are strictly larger than $\sqrt{n}$ and hence $x = a\cdot b > \sqrt{n}^2 = n \geq x$ forms a contradiction.

Even faster: Once we choose to erase all larger multiples of some number, we can choose to start with its square, as all other multiples -- if existent -- have already been taken care of when crossing out multiples of smaller numbers.

This very simple algorithm is implemented in~\autoref{prg:seq_sieve} using the programming language C++.
It initalises an array of size $n-1$ for the numbers $2,\dots, n$ with the value $\mathbf{false}$.
We now interpret $\crosses[i] == \mathbf{true}$ as the number $i+2$ being crossed out, and sequentially go through all numbers up to $n$ and cross out larger multiples of primes as explained above.
Operations involving the variable $\mathrm{numberOps}$ in~\autoref{prg:seq_sieve} are only used for numerically evaluating the cost of the algorithm, which we will come to after analyzing the asymptotic cost.

\begin{proposition}\label{prop:seq_sieve}
	The sequential implementation in~\autoref{prg:seq_sieve} has cost $\bigO(n \log \log n)$.
\end{proposition}
\begin{proof}
	We may assume that computing the square root, and that the allocation of memory has constant cost.
	Then the initialisation of the variables takes $\bigO(n)$ steps.
	The outer loop has at most $\floor{\sqrt{n}}$ iterations and for each iteration, if a prime number $p$ was found, it takes another $\floor{n / p}$ to cross out all larger multiples of $p$.
	Using that the probability that a natural number $x$ is a prime number is about $1/\ln x$, we can bound the overall asymptotic expected cost of the outer loop by
	\[
		\sqrt n + \sum_{\substack{p = 2 \\ \text{$p$ is prime}}}^{\floor{\sqrt{n}}} \frac{n}{p} \leq \sqrt{n} + n \sum_{k = 2}^n \frac{1}{k \ln k}
	\]
	Approximating $\sum_{k=2}^n 1/(k\ln k)$ by the integral $\int_2^n 1 / (x \ln x) \,\mathrm{d}x$ yields the asymptotic bound
	\[
		n \int_2^n \frac{1}{x \ln x}\, \mathrm{d}x = n \left[ \ln(\ln(x)) \right]_2^n = \bigO(n\log\log n ).
	\]
	As the second only iterates through all numbers and collects those numbers that are not crossed out, this proves the proposition.
\end{proof}


\begin{figure}
	\caption{Numerical analysis of the cost of the sequential Sieve of Eratosthenes}
	\centering
	\label{fig:seq_sieve}
	\begin{tikzpicture}
	\begin{loglogaxis}[
	scale only axis,
	width=0.8\textwidth,
	xmin=1,
	ymin=1,
	log basis x=2,
	log basis y=2,
	height=4cm,
	xlabel=$n$, 
	ylabel=$\mathrm{numberOps}$,
	grid=major]
	\addplot[only marks, mark=+] coordinates {
		(2,7)
		(4,23)
		(8,49)
		(16,116)
		(32,244)
		(64,521)
		(128,1078)
		(256,2243)
		(512,4639)
		(1024,9560)
		(2048,19627)
		(4096,40259)
		(8192,82429)
		(16384,168497)
		(32768,343690)
		(65536,700295)
		(131072,1425109)
		(262144,2896784)
		(524288,5882008)
		(1048576,11932592)
		(2097152,24188194)
		(4194304,48993641)
		(8388608,99164080)
		(16777216,200581343)
		(33554432,405485584)
		(67108864,819286034)
		(134217728,1654567969)
		(268435456,3339904925)
		(536870912,6739134949)
		(1073741824,13592834417)
	};
	\end{loglogaxis}
	\end{tikzpicture}
	
	\begin{tikzpicture}
	\begin{semilogxaxis}[
	scale only axis,
	width=0.8\textwidth,
	xmin=1,
	log basis x=2,
	log basis y=2,
	height=4cm,
	xlabel=$n$, 
	ylabel=$\Delta(\mathrm{numberOps})$,
	grid=major]
	\addplot[] coordinates {
		(2.001000,5.750000)
		(4,5.750000)
		(4.001000,6.125000)
		(8,6.125000)
		(8.001000,7.250000)
		(16,7.250000)
		(16.001000,7.625000)
		(32,7.625000)
		(32.001000,8.140625)
		(64,8.140625)
		(64.001000,8.421875)
		(128,8.421875)
		(128.001000,8.761719)
		(256,8.761719)
		(256.001000,9.060547)
		(512,9.060547)
		(512.001000,9.335938)
		(1024,9.335938)
		(1024.001000,9.583496)
		(2048,9.583496)
		(2048.001000,9.828857)
		(4096,9.828857)
		(4096.001000,10.062134)
		(8192,10.062134)
		(8192.001000,10.284241)
		(16384,10.284241)
		(16384.001000,10.488586)
		(32768,10.488586)
		(32768.001000,10.685654)
		(65536,10.685654)
		(65536.001000,10.872719)
		(131072,10.872719)
		(131072.001000,11.050354)
		(262144,11.050354)
		(262144.001000,11.219040)
		(524288,11.219040)
		(524288.001000,11.379807)
		(1048576,11.379807)
		(1048576.001000,11.533830)
		(2097152,11.533830)
		(2097152.001000,11.680994)
		(4194304,11.680994)
		(4194304.001000,11.821280)
		(8388608,11.821280)
		(8388608.001000,11.955580)
		(16777216,11.955580)
		(16777216.001000,12.084412)
		(33554432,12.084412)
		(33554432.001000,12.208313)
		(67108864,12.208313)
		(67108864.001000,12.327492)
		(134217728,12.327492)
		(134217728.001000,12.442115)
		(268435456,12.442115)
		(268435456.001000,12.552617)
		(536870912,12.552617)
		(536870912.001000,12.659314)
		(1073741824,12.659314)
	};
	\end{semilogxaxis}
	\end{tikzpicture}
	
\end{figure}


Now, for the numerical analysis we may assume that summations, mulitplications and taking square roots as well as evaluating comparisons takes one operation.
Then the variable $\mathrm{numberOps}$ counts the number of operations used in~\autoref{prg:seq_sieve}.
The first graph in~\autoref{fig:seq_sieve} shows the number of operations used for a given number $n$.
As expected, the factor of $\log\log n$ does not play any role at first glance as the plot given by the simulation strongly resembles a linear plot.
But having a closer look at the numbers, we can actually find out, that the number of operations is not linear:
Using the difference quotient for intervals $I\coloneqq [2^k, 2^{k+1}]$ defined as
\[\Delta(\mathrm{numberOps})_I\coloneqq \frac{\mathrm{numberOps}(2^{k+1}) - \mathrm{numberOps}(2^{k})}{2^k},\]
we can obtain more fine-grain statements about the growth-rate of the number of operations.
In the second graph of~\autoref{fig:seq_sieve} this series of difference quotients is displayed which shows that the growth is increasing and hence the number of operations is not linear just like in~\autoref{prop:seq_sieve}.
In fact, it supports the statement that the bound in~\autoref{prop:seq_sieve} is asymptotically tight, as the graph resembles the logarithm where the $x$-axis itself is logarithmic.
Hence $\Delta(\mathrm{numberOps})$ resembles $\log\log n$.


\section{A parallel algorithm of the Sieve of Eratosthenes}

When coming up with an idea to parallelise this algorithm, one needs to consider several questions:
What kind of work can be easily parallelised?
How should the numbers be distributed over the processors and what are the implications for designing the parallel algorithm?

First, let us discuss which parts of the algorithm can be worked on simultaneously.
The algorithm roughly consists of two repeated steps:
\begin{enumerate}
	\item Search for the next prime, i.e. the next number that is not crossed out.
	\item Cross out all larger multiples of the selected number.
\end{enumerate}
Trying to parallelise the first step would lead to multiple processors looking for a reasonable number they can use to erase all larger multiples of.
In doing so, it is inevitable that processors might choose some number that turns out not to be prime.
This does not lead to wrong calculations if no number is skipped, because crossing out all larger multiples of a composite number will of course not cross out any prime, but it introduces duplicate work:
If a prime dividing the composite number is chosen by a processor, then all the multiples of the composite number will be checked again.

Hence, the better idea may be to parallelise the second step.
In fact, once a number has been chosen and is known to every processor, each processor can cross out all larger multiples of that number located in its share of all numbers up to $n$.
The next arising question is: Who is responsible for deciding on the multiples of which number to work on next?
It should be a processor which is able to tell the next number that is not crossed out.
Therefore, it makes sense to arrange the numbers in blocks of equal size and start with the first processor to be the so-called \emph{coordinator}, as we know for sure, that for the next couple of iterations the next number, which is not crossed out, will be contained in its block.
Once the processor reaches the end of its block it can transfer the responsibility of coordination on to the next processor.

A benefit of this approach is, that communication between processors is very limited:
In each iteration, the coordinator only has to broadcast either the selected number or the new coordinator.

As we only have to process numbers up to $\sqrt{n}$, a change in coordination responsibility will only be necessary, if there are many processors compared to the number $n$: Each block has $\ceil{n/p}$ numbers, therefore a change of coordinator is not necessary if $p \leq \sqrt{n}$, which is satisfied for high numbers $n$.
Nevertheless, we will take care of this in the algorithm.


\renewcommand{\algorithmicrequire}{\textit{input:}\ \  }
\renewcommand{\algorithmicensure}{\textit{output:}}
\algdef{SE}[DOWHILE]{Do}{doWhile}[1]{\algorithmicdo\ #1}[1]{\algorithmicdo \algorithmicwhile\ #1}%
\algnewcommand{\IIf}[1]{\State\algorithmicif\ #1\ \algorithmicthen}
\algnewcommand{\EndIIf}{\unskip\ \algorithmicend\ \algorithmicif}

\begin{algorithm}
	\caption{Parallel Sieve of Eratosthenes}
	\label{alg:parallel_sieve}
	\begin{algorithmic}[]
		\Require $ n :$ positive number.
		\Ensure $l_1, \dots, l_p :$ list of numbers in each processor, such that their concatenation yields a list of all prime numbers smaller or equal to $n$.
		\State
		\State $\currPrime := 2;$ \Comment{Superstep ($0$)}
		\State $\currCoord := 0;$
		\State $\lastCoord := 0;$
		\State {$\crosses := $ list distributed in blocks $\mathbf{b}_s$ with value $\mathbf{false}$ for indices $2,\dots,n;$}
		\State\While {$\currPrime \leq \sqrt{n}$}
		\State {\{ Sieve with $\currPrime$, if coordinator has not changed \}}\Comment{Superstep ($1_k$)}
		\If {$\currCoord = \lastCoord$}
		\For {$i\in \mathbf{b}_s$ with $i \geq \currPrime^2$ and $i ~\%\,\currPrime = 0$}
		\State $\crosses[i] := \mathbf{true};$
		\EndFor
		\EndIf
		
		\State{\{ Search for next prime or transfer coordination \} }
		\State {$\lastCoord := \currCoord;$}
		\If {$s = \currCoord$}
		\State {\{ Search for next prime \}}
		\Do {$\currPrime++;$}
		\doWhile {$\currPrime \in \mathbf{b}_s$ and $\crosses[\currPrime] = \mathbf{true}$}
		\IIf {$\currPrime \notin \mathbf{b}_s$}{
			$\currCoord++$;
		} \EndIIf
		\EndIf
		
		\State
		\State{\{ Broadcast new information \}}\Comment{Superstep ($2_k$)}
		\If {$s = \lastCoord$}
		\For {$j := 0 ~ \mathbf{to}~ p-1$}
		\State {Put $\currPrime$ to $P(j);$}
		\State {Put $\currCoord$ to $P(j);$}
		\EndFor
		\EndIf
		\EndWhile
		\State
		\State{\{ Accumulate primes in lists \}}\Comment{Superstep ($3$)}
		\State {$l_s := $ empty list}
		\For {$i\in \mathbf{b}_s$ with $\crosses[i] = \mathbf{false}$}
		\State {Append $i$ to $l_s;$}
		\EndFor
	\end{algorithmic}
\end{algorithm}


Bringing all this knowledge into shape yields~\autoref{alg:parallel_sieve}.
In a first step, every processor initialises variables holding the current prime number, the processor id of the current coordinator and an array of boolean values for indices from 2 up to $n$ distributed in blocks.
As in~\autoref{prg:seq_sieve} this list saves for a specific number whether it has been crossed out already.

Now we iterate as long as the current prime is greater than $\sqrt{n}$ and undertake the following two supersteps:
In Superstep ($1_k$) each processor crosses out all larger multiples of the current prime, if the coordinator has not changed since the last iteration.
This is necessary, to be sure that the variable for currentPrime actually holds a prime number and to avoid unnecessary work.
In turn, the coordinator searches for the next prime.
If his search is not successful, it means, that the next prime is to be expected in the block of the next processor.
In that case, he transfers the responsibility for the coordination to the next processor.
In superstep ($2_k$) the coordinator broadcasts this newly gained information to all other processors.
 
Once all numbers up to $\sqrt{n}$ have been processed, we know that the list holding all crosses is finished.
Therefore, we conclude the algorithm with superstep ($3$) by collecting all such numbers of the local block that have not been crossed out and are therefore prime.



Bringing all this knowledge into shape yields~\autoref{alg:parallel_sieve}.
In a first step, every processor initialises variables holding the current prime number, the processor id of the current coordinator and an array of boolean values for indices from 2 up to $n$ distributed in blocks.
As in~\autoref{prg:seq_sieve} this list saves for a specific number whether it has been crossed out already.

Now we iterate as long as the current prime is greater than $\sqrt{n}$ and undertake the following two supersteps:
In Superstep ($1_k$) each processor crosses out all larger multiples of the current prime, if the coordinator has not changed since the last iteration.
This is necessary, to be sure that the variable for currentPrime actually holds a prime number and to avoid unnecessary work.
In turn, the coordinator searches for the next prime.
If his search is not successful, it means, that the next prime is to be expected in the block of the next processor.
In that case, he transfers the responsibility for the coordination to the next processor.
In superstep ($2_k$) the coordinator broadcasts this newly gained information to all other processors.
 
Once all numbers up to $\sqrt{n}$ have been processed, we know that the list holding all crosses is finished.
Therefore, we conclude the algorithm with superstep ($3$) by collecting all such numbers of the local block that have not been crossed out and are therefore prime.

Let us now estimate the BSP cost of this algorithm:
For that, $l$ denotes the latency for synchronization and $g$ denotes the gap between sending successive data words.
Superstep ($0$) costs about $n/p$ for initializing the $\crosses$ array.
The sieving loop of Superstep ($1_k$) is executed once for every prime in $2,\dots,\floor{\sqrt{n}}$.
Similarly to the proof of~\autoref{prop:seq_sieve} we get a cost bound of $4\cdot n/p \cdot \ln(\ln(n))$, where we bound the comparisons and index calculations per loop iteration by 4.
As changing the coordinator does practically not occur for large $n$, we ignore the second part of superstep ($1_k$).
Superstep ($2_k$) now involves a communication in a $2(p-1)$-relation.
As the number of primes smaller than or equal to $n$ is approximately $n/\ln n$, this introduces a cost smaller than $2p\cdot n/\ln n\cdot g$.
Also total number of occurences of supersteps ($1_k$) and ($2_k$) is approximately  $n/\ln n$ introducing a communication cost of $n/\ln n \cdot l$.
The last superstep accumulates all primes in a list which takes every processor only $n/p$ operations.
The synchronization of supersteps ($0$) and ($3$) can be neglected.
Hence the overall estimate of the BSP cost accumulates to
\[
	\frac{2n + 4n \ln \ln n}{p} + \frac{2p n}{\ln n}g + \frac{n}{\ln n} l.
\]

One might consider optimizing the algorithm for a speed improvement:
If we let each processor compute the primes up to $\sqrt{n}$ themselves, we could abandon all communication altogether, but this comes with the expense of an additional memory requirement, hence this improvement was not applied here.

For putting this algorithm into an actual parallel program most efforts went into getting the local indices of the $\crosses$ array right.
The parallel program is implemented in two different ways:
In the first attempt, the program was implemented exactly like the algorithm suggests.
As an optimization, we save half of the space for the $\crosses$ array by ignoring all even numbers, because we know, that $2$ is the only even prime number.
Although ignoring even numbers makes local index computation slightly harder, it does not only save on memory, but as we will see also improves the running time.
The resulting optimised program can be seen in~\autoref{prg:par_opt_sieve}.

Now, let us analyse how the program performs with up to 16 processors.
This benchmark has been made both for the optimised and for unoptimised program.
The results can be seen in\todo{ösdylkfjlsa dök fkjlalkjs dföa dlkj}.
Each value in this figure is the mean running time of 100~iterations to minimize short-term disturbances.
To make sure that these mean values are representative, the relative standard deviation was anlaysed in \todo{aasdlkföj asöldkf alsökjkf} as well.
As expected, for larger values of $n$ the relative standard deviation of the running time get smaller for any number of processes.

Looking at~\autoref{fig:par_opt_sieve} we notice, that the parallelization only has a positive effect once $n$ reaches at least $10^6$.
For $n=10^9$ the speed-up with $16$ processors then is roughly $9.4$.
Interestingly using $8$ processors has already a speed-up of roughly $7.0$ for $n=10^9$.

\begin{figure}
	\caption{Running time analysis of the parallel Sieve of Eratosthenes}
	\label{fig:par_opt_sieve}
	\centering
	\begin{tikzpicture}
	\begin{loglogaxis}[
		scale only axis,
		width=0.8\textwidth,
		log basis x=10,
		log basis y=10,
		ymin=0.000002,
		ymax=200,
		height=6.2cm,
		xlabel=$n$, 
		ylabel=Mean Running Time in $s$,
		title={Unoptimised Program},
		grid=major,
		legend entries={$p=1$,$p=2$,$p=4$,$p=8$,$p=16$},
		legend pos=south east]
		\addplot coordinates {
			(100, 0.0000060000000000000035)
			(1000, 0.000008019999999999986)
			(10000, 0.00005325000000000004)
			(100000, 0.0005608699999999997)
			(1000000, 0.009576549999999998)
			(10000000, 0.16271457)
			(100000000, 6.204124599999999)
			(1000000000, 77.03984354000002)
		};
		
		\addplot coordinates {
			(100, 0.00003313999999999998)
			(1000, 0.000043469999999999995)
			(10000, 0.00011114999999999992)
			(100000, 0.00069373)
			(1000000, 0.005331030000000001)
			(10000000, 0.07657337)
			(100000000, 3.3534415700000006)
			(1000000000, 41.51521570999999)
		};
		\addplot coordinates {
			(100, 0.000052720000000000003)
			(1000, 0.00008104)
			(10000, 0.00018946000000000007)
			(100000, 0.0006461200000000001)
			(1000000, 0.00350927)
			(10000000, 0.03839258)
			(100000000, 2.02312066)
			(1000000000, 21.126782429999995)
		};
		\addplot coordinates {
			(100, 0.00017082000000000002)
			(1000, 0.00026198999999999987)
			(10000, 0.00032855000000000004)
			(100000, 0.00079255)
			(1000000, 0.0033914300000000004)
			(10000000, 0.022402059999999988)
			(100000000, 1.11546878)
			(1000000000, 11.059131900000004)
		};
		
		\addplot coordinates {
			(100, 0.0003873299999999999)
			(1000, 0.0008949600000000001)
			(10000, 0.0011080400000000002)
			(100000, 0.002068410000000001)
			(1000000, 0.00509183)
			(10000000, 0.022208490000000004)
			(100000000, 0.6635081599999999)
			(1000000000, 6.578784989999999)
		};			
		\end{loglogaxis}
	\end{tikzpicture}
	\begin{tikzpicture}
	\begin{loglogaxis}[
	scale only axis,
	width=0.8\textwidth,
	log basis x=10,
	log basis y=10,
	ymin=0.000002,
	ymax=200,
	height=6.2cm,
	xlabel=$n$, 
	ylabel=Mean Running Time in $s$,
	title={Optimised Program},
	grid=major,
	legend entries={$p=1$,$p=2$,$p=4$,$p=8$,$p=16$},
	legend pos=south east]
	\addplot coordinates {
		(100, 0.0000066800000000000055)
		(1000, 0.000010560000000000021)
		(10000, 0.0000605200000000001)
		(100000, 0.0005920100000000001)
		(1000000, 0.00758344)
		(10000000, 0.10046166)
		(100000000, 3.01366798)
		(1000000000, 40.483489250000005)
	};
	\addplot coordinates {
		(100, 0.00008104999999999999)
		(1000, 0.000048960000000000026)
		(10000, 0.00011162999999999999)
		(100000, 0.00049619)
		(1000000, 0.004240320000000002)
		(10000000, 0.049259389999999986)
		(100000000, 1.6486180099999992)
		(1000000000, 21.695564050000016)
	};
	\addplot coordinates {
		(100, 0.000047699999999999994)
		(1000, 0.00009109000000000002)
		(10000, 0.00019095000000000003)
		(100000, 0.0007305999999999999)
		(1000000, 0.003066719999999999)
		(10000000, 0.026568040000000015)
		(100000000, 0.9389143300000005)
		(1000000000, 11.186349019999996)
	};
	\addplot coordinates {
		(100, 0.00045850999999999943)
		(1000, 0.00022281000000000002)
		(10000, 0.0005693099999999997)
		(100000, 0.0008197699999999999)
		(1000000, 0.00289696)
		(10000000, 0.01664076000000001)
		(100000000, 0.4329301399999999)
		(1000000000, 5.802923569999998)
	};
	\addplot coordinates {
		(100, 0.0014837600000000013)
		(1000, 0.0006169300000000001)
		(10000, 0.0008313899999999999)
		(100000, 0.0023080899999999988)
		(1000000, 0.006231130000000005)
		(10000000, 0.01802138)
		(100000000, 0.21772650000000004)
		(1000000000, 4.323914559999998)
	};
	\end{loglogaxis}
	\end{tikzpicture}
\end{figure}


\begin{figure}
	\caption{Relative Standard Deviation of time analysis for~\autoref{fig:par_opt_sieve}}
	\centering
		\begin{tikzpicture}
		\begin{semilogxaxis}[
		scale only axis,
		width=0.4\textwidth,
		log basis x=10,
		log basis y=10,
		height=4cm,
		xlabel=$n$, 
		ylabel=Rel. Deviation,
		ylabel near ticks,
		ymax=7,
		ymin=-0.7,
		title={Unptimised Program},
		grid=major,
		legend entries={$p=1$,$p=2$,$p=4$,$p=8$,$p=16$},
		legend pos=north east]
		\addplot coordinates {
		(100, 0.40340859692355235)
		(1000, 0.02493765586034907)
		(10000, 0.05088096164174562)
		(100000, 0.0038067790454632154)
		(1000000, 0.020418533651413596)
		(10000000, 0.25293744528433115)
		(100000000, 0.025694683169385966)
		(1000000000, 0.01598727793789068)
		
		};
		
		\addplot coordinates {
		(100, 0.1619031789957998)
		(1000, 0.05195169822932531)
		(10000, 0.03367224114302749)
		(100000, 0.13299049994172962)
		(1000000, 0.007874813131699599)
		(10000000, 0.08365855830144216)
		(100000000, 0.026867510650708894)
		(1000000000, 0.009352677348322527)
		
		};
		
		\addplot coordinates {
		(100, 0.11268818784362933)
		(1000, 0.09235632391954453)
		(10000, 0.06085183414294938)
		(100000, 0.8792864002944591)
		(1000000, 0.2516692022670629)
		(10000000, 0.05720230171308279)
		(100000000, 0.09686973651528466)
		(1000000000, 0.015503076214066998)
		
		};
		
		\addplot coordinates {
		(100, 4.367921607554625)
		(1000, 2.5867560883837033)
		(10000, 0.19267169396738515)
		(100000, 0.040107614912353436)
		(1000000, 0.4730480931810351)
		(10000000, 0.12037961490266519)
		(100000000, 0.039864793792599225)
		(1000000000, 0.007970675963974338)
		
		};
		
		\addplot coordinates {
		(100, 2.652328485461903)
		(1000, 2.492576004717528)
		(10000, 1.6978626520383377)
		(100000, 1.147083576080773)
		(1000000, 0.7564426865409155)
		(10000000, 0.3796532603114533)
		(100000000, 0.05581613530071868)
		(1000000000, 0.017534814849470455)
		
		};
		\end{semilogxaxis}
		\end{tikzpicture}
		\begin{tikzpicture}
		\begin{semilogxaxis}[
		scale only axis,
		width=0.4\textwidth,
		log basis x=10,
		log basis y=10,
		ylabel near ticks,
		height=4cm,
		ymax=7,
		ymin=-0.7,
		xlabel=$n$, 
		ylabel=Rel. Deviation,
		title={Optimised Program},
		grid=major,
		legend entries={$p=1$,$p=2$,$p=4$,$p=8$,$p=16$},
		legend pos=north east]
		\addplot coordinates {
		(100, 0.8687065697065419)
		(1000, 0.0799914979806646)
		(10000, 0.02067251364240473)
		(100000, 0.009121704515100443)
		(1000000, 0.013494599693025836)
		(10000000, 0.08534650801677054)
		(100000000, 0.08168939962827118)
		(1000000000, 0.014598962720540154)
		
		};
		
		\addplot coordinates {
		(100, 6.574204637264616)
		(1000, 0.04145585748301211)
		(10000, 0.029523532536101297)
		(100000, 0.806830570679923)
		(1000000, 0.029201241156600208)
		(10000000, 0.0847646784780893)
		(100000000, 0.055673461478022525)
		(1000000000, 0.023508879272757122)
		
		};
		
		\addplot coordinates {
		(100, 0.10807480178922649)
		(1000, 0.08850313225937673)
		(10000, 0.4214093855883432)
		(100000, 1.061044119979381)
		(1000000, 0.1741535452998721)
		(10000000, 0.12907815614428186)
		(100000000, 0.1255578413818158)
		(1000000000, 0.008339998856569752)
		
		};
		
		\addplot coordinates {
		(100, 2.675417731532113)
		(1000, 2.023031176887656)
		(10000, 2.3191086389231472)
		(100000, 0.16406770559612774)
		(1000000, 0.305689773744763)
		(10000000, 0.1291424157428458)
		(100000000, 0.0997100269349392)
		(1000000000, 0.005162268199345419)
		
		};
		
		\addplot coordinates {
		(100, 2.5428150071275124)
		(1000, 3.611545332160197)
		(10000, 1.776395545957089)
		(100000, 1.8983872605331447)
		(1000000, 1.0257164507406025)
		(10000000, 0.4474433103897337)
		(100000000, 0.1606753105874427)
		(1000000000, 0.0311778237194774)
		
		};
		\end{semilogxaxis}
		\end{tikzpicture}
\end{figure}	



\pagebreak
\appendix
\section{Appendix}

 	\begin{lstlisting}[caption={Sequential implementation of the Sieve of Eratosthenes}, label={prg:seq_sieve}, frame={single}]
#include <cstdio>
#include <cmath>
#include <vector>

long numberOps = 0;

std::vector<long> sieve(long n) {
  bool *crosses = new bool[n - 1]();
  // list[i] == true means i+2 is crossed out.
  // new bool[n-1]() automatically initializes the array with false.
  double maxIter = sqrt(n) - 2;

  numberOps += n + 1;
  for (long i = 0; i <= maxIter; i++) {
    if (!crosses[i]) { // cross out all larger multiples of i+2
      for (int j = (i+2)*(i+2) - 2; j < n - 1; j += (i+2)) {
        crosses[j] = true;
        numberOps += 3;
      }
    }
    numberOps += 3;
  }

  std::vector<long> primes;
  primes.reserve(n / log(n)); // n/ln(n) is average number of primes <= n
  for (long i = 0; i < n - 1; i++) {
    if (!crosses[i]) primes.push_back(i+2);
    numberOps += 4;
  }

  delete [] crosses;
  return primes;
}
	\end{lstlisting}

	\begin{lstlisting}[caption={Optimised parallel program for the Sieve of Eratosthenes}, label={prg:par_opt_sieve}, frame={single}]
#include <bsp.hpp>
#include <cmath>
#include <vector>

void bsp_sieve_optimised() {
  bsp_begin(P);
  double time0 = bsp_time();
  long p = bsp_nprocs(), s = bsp_pid();

  // We only consider odd numbers to save on memory and enhance performance
  long globalArrayLength = (n - 1) / 2;
  long arrayLength = (long) ceil(((double) globalArrayLength) / p);
  long blockStart = 2 * s * arrayLength + 3;
  bool *crosses = new bool[arrayLength]();
  // We start sieving with prime 3; the first coordinator is processor 0.
  long currPrime = 3, currCoordinator = 0, lastCoordinator = 0;
  bsp_push_reg(&currPrime, sizeof(long));
  bsp_push_reg(&currCoordinator, sizeof(long));
  bsp_sync();

  long maxSievePrime = (long) sqrt(n);
  while (currPrime <= maxSievePrime) {
    // Sieve, if the coordinator did not change
    if (lastCoordinator == currCoordinator)
      sieve_optimised(currPrime, crosses, blockStart, arrayLength);

    // Let coordinator change current prime or coordinator
    if (s == currCoordinator) {
      // Search for the next prime in local array
      long j = (currPrime - blockStart) / 2
               + (lastCoordinator == currCoordinator);
      while (j < arrayLength && crosses[j]) j++;
      // Translate back to normal representation
      currPrime = blockStart + j * 2;
      lastCoordinator = currCoordinator;
      // If j exceeds the local array, transfer coordination to next proc.
      currCoordinator = j < arrayLength ? s : s + 1;
    } else lastCoordinator = currCoordinator;
    bsp_sync();

    // Distribute information
    if (s == lastCoordinator) {
      for (long k = 0; k < p; k++) {
        bsp_put(k, &currCoordinator, &currCoordinator, 0, sizeof(long));
        bsp_put(k, &currPrime, &currPrime, 0, sizeof(long));
      }
    }
    bsp_sync();
  }

  // Accumulate all local primes in list
  std::vector<long> primes;
  primes.reserve(n / log(n)); // n/ln(n) is average number of primes <= n
  for (long k = 0; k < arrayLength; k++) {
    if (!crosses[k]) primes.push_back(2*k+3);
  }
  delete[] crosses;
  bsp_pop_reg(currPrime);
  bsp_pop_reg(currCoordinator);
  bsp_sync();

  double time1 = bsp_time();
  if (s == 0) {
    timeTaken = time1 - time0;
  }
  
  // Do something with primes

  primes.clear();
  bsp_end();
}

void sieve_optimised(long prime, bool * crosses,
                     long blockStart, long arrayLength) {
  // Search for first multiple of prime in local array
  // Start with prime^2 and check if it is prior to the local array
  long j = (prime*prime - blockStart) / 2;
  if (j < 0) {
    // If so, take the first multiple of prime in local array:
    long mod = blockStart % prime;
    // If the remainder `mod` is ...
    if (mod == 0) j = 0;// zero, j=0 represents the first multiple
    else if (mod%2 == 1) j = (prime - mod)/2; // odd, advance by prime-mod.
    else j = (2 * prime - mod) / 2; // even, advance by 2*prime-mod
  }
  // Now cross out all multiples of the prime starting with j
  while (j < arrayLength) {
    crosses[j] = true;
    j += prime; // Step size: 2*prime/2; ignore even multiples.
  }
}
	\end{lstlisting}

	\begin{lstlisting}[caption={Extension function for finding prime twins}, label={prg:par_opt_sieve}, frame={single}]
#include <bsp.hpp>
#include <vector>

/* Returns list of twins represented by their mean */
std::vector<long> bsp_twins(std::vector<long> primes) {
  long p = bsp_nprocs(), s = bsp_pid();
  // Get largest prime of previous processor
  long prevPrime = s == 0 ? 2 : 0;
  bsp_push_reg(&prevPrime, sizeof(long));
  bsp_sync();

  if (s < p - 1 && primes.size() > 0)
    bsp_put(s + 1, &primes[primes.size() - 1],
            &prevPrime, 0, sizeof(long));
  bsp_sync();

  std::vector<long> twins;
  if (primes.size() == 0)
    return twins;

  if (prevPrime + 2 == primes[0])
    twins.push_back(prevPrime + 1);
  for (long i = 0; i < primes.size() - 1; i++) {
    if (primes[i] + 2 == primes[i + 1])
      twins.push_back(primes[i] + 1);
  }

  bsp_pop_reg(&prevPrime);
  bsp_sync();
  return twins;
}
	\end{lstlisting}
	
	
	\begin{lstlisting}[caption={Extension function for checking the Goldbach conjecture}, label={prg:par_opt_sieve}, frame={single}]
void bsp_goldbach(std::vector<long> primes) {
  long p = bsp_nprocs(), s = bsp_pid();
  long globalArrayLength = ceil(((double) n) / 2);
  long arrayLength = ceil(((double) globalArrayLength) / p);
  // proc i manages [2*i*arrayLength, ..., 2*(i+1)*arrayLength)

  long * numberPrimes = new long[p];
  bsp_push_reg(numberPrimes, p*sizeof(long));
  numberPrimes[s] = primes.size();
  bsp_sync();

  for (long i = s + 1; i < p; i++)
    bsp_put(i, &numberPrimes[s], numberPrimes, s*sizeof(long), sizeof(long));
  bsp_sync();

  // Make space for necessary primes
  long numberNecPrimes = 0;
  for (long i = 0; i <= s; i++) numberNecPrimes += numberPrimes[i];
  long * necPrimes = new long [numberNecPrimes];

  long ** primeBlocks = new long*[s+1];
  primeBlocks[0] = necPrimes;
  for (long i = 1; i <= s; i++) primeBlocks[i] = primeBlocks[i-1] + numberPrimes[i-1];

  std::copy(primes.begin(), primes.end(), primeBlocks[s]);

  bsp_push_reg(necPrimes, numberNecPrimes*sizeof(long));

  bool * crosses = new bool[arrayLength]();
  // Cross out 0 and 2.
  if (s == 0) crosses[0] = crosses[1] = true;
  bsp_sync();

  // Every processor needs to cross out using blocks i,j with i+j=s or i+j+1=s
  long high, low;
  high = low = s/2;
  for (long iter = 0; iter < p; iter++) {
    if (low < 0 || high > s) {
      bsp_sync();
      continue;
    }
    if (low + high == s && high != s)
      bsp_get(high, necPrimes, (primeBlocks[high] - necPrimes) * sizeof(long),
              primeBlocks[high], numberPrimes[high] * sizeof(long));
    else if (low + high + 1 == s)
      bsp_get(low, necPrimes, (primeBlocks[low] - necPrimes) * sizeof(long),
              primeBlocks[low], numberPrimes[low] * sizeof(long));
    bsp_sync();

    for (long i = 0; i < numberPrimes[high]; i++) {
      long maxPrime = (s+1)*2*arrayLength - primeBlocks[high][i];
      for (long j = 0; j < numberPrimes[low] && primeBlocks[low][j] < maxPrime; j++) {
        long crossOut = primeBlocks[high][i] + primeBlocks[low][j];
        if (crossOut%2 == 0 && crossOut >= s*2*arrayLength)
          crosses[(crossOut - s*2*arrayLength) / 2] = true;
      }
    }
    if (low + high + 1 == s) high++;
    else low--;
  }

  // Check the conjecture
  for (long i = 0; i < arrayLength; i++) {
    if (!crosses[i] && (s*arrayLength + i)*2 <= n)
      printf("Found counterexample: %li!\n", (s*arrayLength + i)*2);
  }

  delete [] crosses;
  bsp_pop_reg(necPrimes);
  bsp_pop_reg(numberPrimes);
  delete [] primeBlocks;
  delete [] numberPrimes;
}
	\end{lstlisting}

\end{document}